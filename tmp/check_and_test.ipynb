{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c514a8ef",
   "metadata": {},
   "source": [
    "### How to run a jupyter notebook through a remote server on local machine:\n",
    "https://stackoverflow.com/questions/69244218/how-to-run-a-jupyter-notebook-through-a-remote-server-on-local-machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2677e38d-b480-4d7d-a5ad-c25454e0d46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc09485-0178-49e6-8b0a-d83db13602e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 3.10.18 | packaged by conda-forge | (main, Jun  4 2025, 14:45:41) [GCC 13.3.0]\n",
      "environment: /home/aclexp/mambaforge/envs/quanta\n"
     ]
    }
   ],
   "source": [
    "print(\"version:\", sys.version)\n",
    "print(\"environment:\", sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7986992b-3399-4957-849d-f6fe12ca7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e4f01e5-7680-4871-8ab4-2e772de8f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92ca08ff-68f5-4a91-931f-017399b66f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a1dd7f-be83-4b12-a5bc-809dfbc07d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a8edb7-5063-4c71-93ae-ce399c42c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv(os.path.join(\"..\", \"data\", \"rawdata\", \"DATA_ses-01_2024-12-09.csv\"))\n",
    "DF.rename(columns={\"BASIC_INFO_ID\": \"ID\"}, inplace=True)\n",
    "\n",
    "inclusion_df = pd.read_csv(os.path.join(\"..\", \"data\", \"rawdata\", \"InclusionList_ses-01.csv\"))\n",
    "inclusion_df = inclusion_df.query(\"MRI == 1\")\n",
    "\n",
    "DF = pd.merge(DF, inclusion_df[[\"ID\"]], on=\"ID\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54335d09-75e5-46e7-beff-f52a4497dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.drop(columns=[\n",
    "    col for col in DF.columns \n",
    "    if ( \"RESTING\" in col )\n",
    "    or ( col.startswith(\"LANGUAGE_SPEECHCOMP_BEH\") and col.endswith(\"RT\") )\n",
    "    or ( col.startswith(\"MOTOR_GOFITTS_EEG\") and ((\"Diff\" in col) or (\"Slope\" in col)) )\n",
    "    or ( col.startswith(\"MEMORY_EXCLUSION_BEH\") and any( kw in col for kw in [\"TarMiss\", \"NewFA\", \"NonTarFA_PROPORTION\", \"C2NonTarFA_RT\", \"C3NonTarFA_RT\", \"C1NewCR_PROPORTION\", \"C1NewCR_RTvar\"] ) )\n",
    "    or ( col.startswith(\"MEMORY_EXCLUSION_EEG\") and any( kw in col for kw in [\"TarHitNewCRdiff\", \"NonTarCRNewCRdiff\"] ) )\n",
    "    or ( col.startswith(\"MEMORY_OSPAN_EEG\") and any( kw in col for kw in [\"150To350\", \"AMPLITUDE\"] ) )\n",
    "    or ( col.startswith(\"MEMORY_MST_MRI\") and any( kw in col for kw in [\"OldCorSimCorDiff\", \"OldCorNewCorDiff\", \"SimCorNewCorDiff\", \"MD\"] ) )\n",
    "], inplace=True)\n",
    "\n",
    "DF.drop(columns=[\n",
    "    \"MEMORY_OSPAN_EEG_MathItem01_PZ_250To450_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem23_PZ_250To450_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem456_PZ_250To450_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem01_PZ_400To600_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem23_PZ_400To600_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem456_PZ_400To600_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem01_O1_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem23_O1_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem456_O1_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem01_O2_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem23_O2_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem456_O2_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem01_OZ_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem23_OZ_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem456_OZ_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem01_PZ_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem23_PZ_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem456_PZ_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem2301Diff_O1_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem2301Diff_O2_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem2301Diff_OZ_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem45601Diff_O1_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem45601Diff_O2_600To800_4To8_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem01_PZ_1200To1400_20To25_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem23_PZ_1200To1400_20To25_POWER\", \n",
    "    \"MEMORY_OSPAN_EEG_MathItem456_PZ_1200To1400_20To25_POWER\"\n",
    "], inplace=True)\n",
    "\n",
    "for col in DF.columns:\n",
    "    if re.match(r\"MOTOR_GFORCE_MRI_.*?HighForce_.*?H_.*?_[a-zA-Z]+\", col):\n",
    "        pair = col.replace(\"High\", \"Low\")\n",
    "        DF.insert(\n",
    "            DF.columns.get_loc(col), \n",
    "            col.replace(\"High\", \"Mean\"), \n",
    "            DF[[col, pair]].mean(axis=1)\n",
    "        )\n",
    "        DF.drop(\n",
    "            columns=[col, pair], \n",
    "            inplace=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401421e-c3d3-4d0c-b151-2b80912399ae",
   "metadata": {},
   "source": [
    "## Select features by specified domains and approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1f633-65b5-4596-922f-e941ec10f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_features = [ \n",
    "    col for col in DF.columns\n",
    "    if any( domain in col for domain in [\"STRUCTURE\", \"MOTOR\", \"MEMORY\", \"LANGUAGE\"] )\n",
    "    and any( approach in col for approach in [\"MRI\", \"BEH\", \"EEG\"] )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274aa138-44ec-492d-99ac-0170ecce7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DF.loc[:, included_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d773540-a9d7-4e7f-9d0e-e4cd070d340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af887eec-4150-4920-9f11-1b44147fa9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_f = categorize_features(X.columns)\n",
    "\n",
    "# for f in sorted(cat_f.keys()):\n",
    "#     print(f\"# {f}: {len(cat_f[f])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c60a9-4c6c-4c26-b7d3-e5d397d0864b",
   "metadata": {},
   "source": [
    "## Remove features with too many missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5f1565-d398-4427-b415-ea93ae0c58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_subjs = len(X)\n",
    "na_rates = pd.Series(X.isnull().sum() / n_subjs)\n",
    "\n",
    "Q1 = na_rates.quantile(.25)\n",
    "Q3 = na_rates.quantile(.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = na_rates[na_rates > (Q3 + IQR * 1.5)]\n",
    "\n",
    "print(\n",
    "    f\"{len(outliers)} out of {len(na_rates)} features have too many missing values (> {round(Q3 + IQR * 1.5, 2)}).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a453a-bf77-4760-9e3c-e14bdaae1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 1.2))\n",
    "ax.boxplot(na_rates, vert=False)\n",
    "ax.axvspan(Q3 + IQR * 1.5, na_rates.max(), color='r', alpha=0.2)\n",
    "ax.set_xlabel(\"Missing Rate\")\n",
    "ax.set_yticklabels(\"\")\n",
    "plt.tight_layout()\n",
    "plt.plot()\n",
    "# plt.savefig(os.path.join(\"derivatives\", \"na_rates_boxplot.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d1a1a0-62b1-4c9d-8165-4a63343f14b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f6f6f-1d7c-4871-8379-ad4a50976bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = X.drop(columns=outliers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0998e8-4c61-4937-a885-e3232106ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_cleaned.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b6cd7-3fa3-485b-8c24-0f30bcad39e0",
   "metadata": {},
   "source": [
    "## Fill missing values with median and standardize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d76953-88e7-4e92-8cf9-de000f523b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X_cleaned), columns=X_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14db87-4506-45f2-9c6c-dfb358cd9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X_imputed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e4e3d7-6943-4017-b6a4-69a6a0e808b7",
   "metadata": {},
   "source": [
    "## Calculate VIF \n",
    "##### See: https://stats.stackexchange.com/questions/461141/is-it-advisable-to-impute-missing-values-and-scale-features-before-computing-the\n",
    "##### Also: https://stackoverflow.com/questions/42658379/variance-inflation-factor-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c34a7-9204-4da6-908e-5ff138d9d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def variance_inflation_factor(X: np.ndarray, idx: int):\n",
    "#     mask = np.arange(X.shape[1]) != idx\n",
    "#     X_i = X[:, idx]\n",
    "#     X_else = X[:, mask]\n",
    "#     reg = LinearRegression(fit_intercept=True).fit(X_else, X_i)\n",
    "#     Xi_pred = reg.predict(X_else)\n",
    "#     R_sq = reg.score(X_else, X_i)\n",
    "#     # ss_tot = np.sum((X_i - np.mean(X_i)) ** 2)\n",
    "#     # ss_res = np.sum((X_i - Xi_pred) ** 2)\n",
    "#     # R_sq = 1 - (ss_res / ss_tot)\n",
    "#     vif = 1 / max(1 - R_sq, 1e-16)\n",
    "#     return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15c265-2b0d-4ecf-a181-5422686d02a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vif_values = pd.Series(\n",
    "#     [ variance_inflation_factor(X_scaled.values, i) for i in range(X_scaled.shape[1]) ], \n",
    "#     index=X_scaled.columns, \n",
    "#     name='VIF'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc49094-0a93-48ae-8182-bfea006f12f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406bfab8-416e-48ee-a34e-a86bf33e8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_ = add_constant(X_scaled)\n",
    "# vif_values = pd.Series(\n",
    "#     [ variance_inflation_factor(X_.values, i) for i in range(X_.shape[1]) ], \n",
    "#     index=X_.columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39cacde-2d66-48ad-be0f-7002e78f87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vifs = pd.Series(\n",
    "#     np.linalg.inv(X_scaled.corr().to_numpy()).diagonal(), # pseudo-inverse\n",
    "#     index=X_scaled.columns, \n",
    "#     name='VIF'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e759599-0f89-45de-bece-a2a8ee06bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vifs = vifs.sort_values(by=\"VIF\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9368f75-fee2-4d1a-844b-da6723d633f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vifs[vifs.abs() < 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88769109-3164-4dac-a108-46373d36eb14",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469e4ad-53be-43b1-9c72-0b1f2842ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_cormat = X_scaled.corr()\n",
    "# X_corr = X_cormat.stack().reset_index()\n",
    "# X_corr.columns = ['FEATURE_1', 'FEATURE_2', 'CORRELATION']\n",
    "# print(X_corr.describe().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59de6d6-97fd-4264-98d3-d0cc3e6c7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_corr['CORRELATION'] > .8).sum() / len(X_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cfb1da-492a-4140-8971-9d13877c727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_cormat.to_csv(os.path.join(\"derivatives\", \"Feature cormat.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4a263-2670-4f45-a4c7-af578ef88863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(X_cormat, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502355f9-4e51-4364-b704-19657c26794b",
   "metadata": {},
   "source": [
    "## Categorize features based on knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234f3da-21d4-42d6-8b90-309cc0c72df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_GM_features = {\n",
    "    \"GySulFrontoMargin\": \"FT\", # Fronto-marginal gyrus (of Wernicke) and sulcus\n",
    "    \"GySulSubCentral\": \"FT\", # Subcentral gyrus (central operculum) and sulci\n",
    "    \"GySulTransvFrontopol\": \"FT\", # Transverse frontopolar gyri and sulci\n",
    "    \"GyFrontInfOpercular\": \"FT\", # Opercular part of the inferior frontal gyrus\n",
    "    \"GyFrontInfObital\": \"FT\", # Orbital part of the inferior frontal gyrus\n",
    "    \"GyFrontInfTriangul\": \"FT\", # Triangular part of the inferior frontal gyrus\n",
    "    \"GyFrontMiddle\": \"FT\", # Middle frontal gyrus (F2)\n",
    "    \"GyFrontSup\": \"FT\", # Superior frontal gyrus (F1)\n",
    "    \"GyOrbital\": \"FT\", # Orbital gyri\n",
    "    \"GyRectus\": \"FT\", # Straight gyrus, Gyrus rectus\n",
    "    \"LateralFisAnterorHorizont\": \"FT\", # Horizontal ramus of the anterior segment of the lateral sulcus (or fissure)\n",
    "    \"LateralFisAnterorVertical\": \"FT\", # Vertical ramus of the anterior segment of the lateral sulcus (or fissure)\n",
    "    \"LateralFisPost\": \"FT\", # Posterior ramus (or segment) of the lateral sulcus (or fissure)\n",
    "    \"SulFrontInferior\": \"FT\", # Inferior frontal sulcus\n",
    "    \"SulFrontMiddle\": \"FT\", # Middle frontal sulcus\n",
    "    \"SulFrontSuperior\": \"FT\", # Superior frontal sulcus\n",
    "    \"SulOrbitalLateral\": \"FT\", # Lateral orbital sulcus\n",
    "    \"SulOrbitalMedialOlfact\": \"FT\", # Medial orbital sulcus (olfactory sulcus)\n",
    "    \"SulOrbitalHshaped\": \"FT\", # Orbital sulci (H-shaped sulci)\n",
    "    \"SulSubOrbital\": \"FT\", # Suborbital sulcus (sulcus rostrales, supraorbital sulcus)\n",
    "    \"GyOccipitalTemporalLateralFusifor\": \"FT\", # Lateral occipito-temporal gyrus (fusiform gyrus, O4-T4)\n",
    "    \"GyOccipitalTemporalMedialParahip\": \"FT\", # Parahippocampal gyrus, parahippocampal part of the medial occipito-temporal gyrus, (T5)\n",
    "    \"GyTemporalSuperiorGyTemporalTransv\": \"FT\", # Anterior transverse temporal gyrus (of Heschl)\n",
    "    \"GyTemporalSuperiorLateral\": \"FT\", # Lateral aspect of the superior temporal gyrus\n",
    "    \"GyTemporalSuperiorPlanPolar\": \"FT\", # Planum polare of the superior temporal gyrus\n",
    "    \"GyTemporalSuperiorPlanTempo\": \"FT\", # Planum temporale or temporal plane of the superior temporal gyrus\n",
    "    \"GyTemporalInferior\": \"FT\", # Inferior temporal gyrus (T3)\n",
    "    \"GyTemporalMiddle\": \"FT\", # Middle temporal gyrus (T2)\n",
    "    \"PoleTemporal\": \"FT\", # Temporal pole\n",
    "    \"SulOccipitalTemporalLateral\": \"FT\", # Lateral occipito-temporal sulcus\n",
    "    \"SulOccipitalTemporalMedialAndLingual\": \"FT\", # Medial occipito-temporal sulcus (collateral sulcus) and lingual sulcus\n",
    "    \"SulTemporalInferior\": \"FT\", # Inferior temporal sulcus\n",
    "    \"SulTemporalSuperior\": \"FT\", # Superior temporal sulcus (parallel sulcus)\n",
    "    \"SulTemporalTransverse\": \"FT\", # Transverse temporal sulcus\n",
    "    \"GySulCingulAnt\": \"IC\", # Anterior part of the cingulate gyrus and sulcus (ACC)\n",
    "    \"GySulCingulMidAnt\": \"IC\", # Middle-anterior part of the cingulate gyrus and sulcus (aMCC)\n",
    "    \"GySulCingulMidPost\": \"IC\", # Middle-posterior part of the cingulate gyrus and sulcus (pMCC)\n",
    "    \"GyCingulPostDorsal\": \"IC\", # Posterior-dorsal part of the cingulate gyrus (dPCC)\n",
    "    \"GyCingulPostVentral\": \"IC\", # Posterior-ventral part of the cingulate gyrus (vPCC, isthmus of the cingulate gyrus)\n",
    "    \"GyInsularLongSulCentralInsular\": \"IC\", # Long insular gyrus and central sulcus of the insula\n",
    "    \"GyInsularShort\": \"IC\", # Short insular gyri\n",
    "    \"GySubcallosal\": \"IC\", # Subcallosal area, subcallosal gyrus\n",
    "    \"SulCircularInsulaAnteror\": \"IC\", # Anterior segment of the circular sulcus of the insula\n",
    "    \"SulCircularInsulaInferior\": \"IC\", # Inferior segment of the circular sulcus of the insula\n",
    "    \"SulCircularInsulaSuperoir\": \"IC\", # Superior segment of the circular sulcus of the insula\n",
    "    \"SulPericallosal\": \"IC\", # Pericallosal sulcus (S of corpus callosum)\n",
    "    \"GySulOccipitalInf\": \"PO\", # Inferior occipital gyrus (O3) and sulcus\n",
    "    \"GyCuneus\": \"PO\", # Cuneus (O6)\n",
    "    \"GyOccipitalMiddle\": \"PO\", # Middle occipital gyrus (O2, lateral occipital gyrus)\n",
    "    \"GyOccipitalSup\": \"PO\", # Superior occipital gyrus (O1)\n",
    "    \"GyOccipitalTemporalMedialLingual\": \"PO\", # Lingual gyrus, ligual part of the medial occipito-temporal gyrus, (O5)\n",
    "    \"PoleOccipital\": \"PO\", # Occipital pole\n",
    "    \"SulCalcarine\": \"PO\", # Calcarine sulcus\n",
    "    \"SulCollatTransvAnterior\": \"PO\", # Anterior transverse collateral sulcus\n",
    "    \"SulCollatTransvPosterior\": \"PO\", # Posterior transverse collateral sulcus\n",
    "    \"SulOccipitalMiddleAndLunatus\": \"PO\", # Middle occipital sulcus and lunatus sulcus\n",
    "    \"SulOccipitalSuperiorAndTransversal\": \"PO\", # Superior occipital sulcus and transverse occipital sulcus\n",
    "    \"SulOccipitalAnterior\": \"PO\", # Anterior occipital sulcus and preoccipital notch (temporo-occipital incisure)\n",
    "    \"SulParietoOccipital\": \"PO\", # Parieto-occipital sulcus (or fissure)\n",
    "    \"GySulParaCentral\": \"PO\", # Paracentral lobule and sulcus\n",
    "    \"GyParietalInfAngular\": \"PO\", # Angular gyrus\n",
    "    \"GyParietalInfSupramar\": \"PO\", # Supramarginal gyrus\n",
    "    \"GyParietalSuperior\": \"PO\", # Superior parietal lobule\n",
    "    \"GyPostCentral\": \"PO\", # Postcentral gyrus\n",
    "    \"GyPreCentral\": \"PO\", # Precentral gyrus\n",
    "    \"GyPreCuneus\": \"PO\", # Precuneus (medial part of P1)\n",
    "    \"SulCentral\": \"PO\", # Central sulcus (Rolando's fissure)\n",
    "    \"SulCingulMarginalis\": \"PO\", # Marginal branch (or part) of the cingulate sulcus\n",
    "    \"SulIntermPrimJensen\": \"PO\", # Sulcus intermedius primus (of Jensen)\n",
    "    \"SulIntraParietAndParietalTrans\": \"PO\", # Intraparietal sulcus (interparietal sulcus) and transverse parietal sulci\n",
    "    \"SulPostCentral\": \"PO\", # Postcentral sulcus\n",
    "    \"SulPreCentralInferiorPart\": \"PO\", # Inferior part of the precentral sulcus\n",
    "    \"SulPreCentralSuperiorPart\": \"PO\", # Superior part of the precentral sulcus\n",
    "    \"SulSubParietal\": \"PO\" # Subparietal sulcus\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350663d6-652b-4c82-ab29-fde8a6e4a5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_categorized_GM = {\n",
    "    k.lower(): v\n",
    "    for k, v in categorized_GM_features.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6598ee90-9924-4e82-982f-a9c6f586ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_features(included_features):\n",
    "    categorized_features = {}\n",
    "    \n",
    "    for feature in included_features:\n",
    "        if feature.startswith(\"STRUCTURE\"):\n",
    "            category, hemi, area, measure = feature.split(\"_\")[3::]\n",
    "            if category == \"NULL\":\n",
    "                f = f\"STR ({category}, {measure})\"\n",
    "            else:\n",
    "                if (category == \"GM\") and (measure != \"FA\"): \n",
    "                    region = lower_categorized_GM[area.lower()]\n",
    "                    \n",
    "                    if region == \"IC\":\n",
    "                        f = f\"STR ({category}, {region}, {measure})\"\n",
    "                    else:\n",
    "                        f = f\"STR ({category}, {hemi[0]}, {region}, {measure})\"\n",
    "                else:\n",
    "                    f = f\"STR ({category}, {hemi[0]}, {measure})\"\n",
    "        else:\n",
    "            domain, task, measure, condition = feature.split(\"_\")[:4]\n",
    "            measure = \"fMRI\" if measure == \"MRI\" else measure                \n",
    "\n",
    "            if domain == \"LANGUAGE\":\n",
    "                f = f\"{measure} ({domain.lower()})\"\n",
    "                \n",
    "            elif (measure == \"EEG\") and (task == \"OSPAN\") and (\"Diff\" in condition):\n",
    "                f = f\"{measure} ({domain.lower()}, {task.lower()} diff)\"\n",
    "                \n",
    "            elif (measure == \"EEG\") and (task == \"GOFITTS\"):\n",
    "                suffix = re.sub(r\"[0-9]+\", \"\", condition).replace(\"ID\", \"\").replace(\"W\", \"\").replace(\"Slope\", \" slope\")\n",
    "                f = f\"{measure} ({domain.lower()}, {task.lower()} {suffix.lower()})\"\n",
    "            \n",
    "            else:\n",
    "                f = f\"{measure} ({domain.lower()}, {task.lower()})\"\n",
    "\n",
    "        if f in categorized_features.keys():\n",
    "            categorized_features[f].append(feature)\n",
    "        else:\n",
    "            categorized_features.update({f: [feature]})\n",
    "    \n",
    "    return categorized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b495e25-1c4d-4a4a-b3bc-48e913795f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_features = categorize_features(X_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b8540-8661-4e79-9a03-29beddfc36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = True\n",
    "# ALL = False \n",
    "\n",
    "t = 0\n",
    "for f in sorted(categorized_features.keys()):\n",
    "    c = len(categorized_features[f])\n",
    "    if (c > 36) or ALL:\n",
    "        print(f\"# {f}: {c}\")\n",
    "        t += c\n",
    "        \n",
    "print(\"\\n\", t, \"\\n\", len(categorized_features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cfc51d-986a-4e65-a400-297c8197a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([ len(v) for v in categorized_features.values() ]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5956866c-1efd-4dc3-9ecd-e61b7d922935",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_outliers = categorize_features(outliers.index)\n",
    "\n",
    "for f in sorted(categorized_outliers.keys()):\n",
    "    print(f\"# {f}: {len(categorized_outliers[f])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce2682-b1f6-4cae-b09a-f0018519669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_splited = {}\n",
    "for f in categorized_features.keys():\n",
    "    X_splited[f] = X_scaled.loc[:, categorized_features[f]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718664e7-1111-4640-91f1-9bacdf46065e",
   "metadata": {},
   "source": [
    "## Combining variables using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9e8d9-d5e3-4f14-8fa0-2966a9188857",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/62303782/is-there-a-way-to-conduct-a-parallel-analysis-in-python\n",
    "## https://www.statstodo.com/ParallelAnalysis.php\n",
    "\n",
    "def parallel_analysis(X, n_iter=100, seed=42):\n",
    "    n_components = X.shape[1] - 1\n",
    "    pca = PCA(n_components, random_state=seed)\n",
    "    X_transformed = pca.fit_transform(X)\n",
    "    eigenvalues = pca.explained_variance_ratio_\n",
    "\n",
    "    random_eigenvalues = np.zeros(shape=(n_iter, n_components))\n",
    "    for i in range(n_iter): # Monte Carlo simulation\n",
    "        X_r = np.random.normal(loc=0, scale=1, size=X.shape) # random data\n",
    "        pca_r = PCA(n_components, random_state=42)\n",
    "        X_r_transformed = pca_r.fit_transform(X_r)\n",
    "        random_eigenvalues[i, :] = pca_r.explained_variance_ratio_\n",
    "    \n",
    "    rand_eigv_mean = random_eigenvalues.mean(axis=0)\n",
    "    rand_eigv_std = random_eigenvalues.std(axis=0)\n",
    "    thresholds = rand_eigv_mean + rand_eigv_std * 1.64 # the 95th percentile\n",
    "    n_retained = max(np.argwhere(eigenvalues > thresholds)) + 1\n",
    "\n",
    "    return n_retained, eigenvalues, random_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb33c5-fd34-43d9-86a3-e205cb918b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(X, threshold=0.9):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_cormat = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [ column for column in upper_cormat.columns if any(upper_cormat[column] > threshold) ]\n",
    "    return X.drop(columns=to_drop), to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a55a5-522d-4eee-ae50-9a0666b1db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_features = {}\n",
    "n_retained_comps = {}\n",
    "\n",
    "for f, X_n in X_splited.items():\n",
    "    X_n, dropped_features[f] = remove_highly_correlated_features(X_n)    \n",
    "    n_components, eigv_raw, eigv_rand = parallel_analysis(X_n)\n",
    "    n_retained_comps[f] = n_components[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea49be0-1cd7-474c-8ba6-85ff539c5098",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "for f in sorted(n_retained_comps.keys()):\n",
    "    c = n_retained_comps[f]\n",
    "    print(f\"# {f}: {c} [{len(dropped_features[f])}]\")\n",
    "    t += c\n",
    "\n",
    "print(\"\\n\", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2a40b-26ec-40d3-b33e-fbcfac8f1625",
   "metadata": {},
   "source": [
    "## Else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7a8b2c-3075-4752-9bb8-15d4b4fffcac",
   "metadata": {},
   "source": [
    "##### Mundfrom, D. J., Shaw, D. G., & Ke, T. L. (2005). Minimum sample size recommendations for conducting factor analyses. https://doi.org/10.1207/s15327574ijt0502_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20695a2c-df2f-4cd3-8031-4e8c7b5d853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_DF_list = [\n",
    "    DF[DF[\"BASIC_INFO_AGE\"].between(lb, ub)] for lb, ub in [(0, 44), (45, np.inf)]\n",
    "]\n",
    "\n",
    "print(len(DF) / 5)\n",
    "\n",
    "for sub_DF in sub_DF_list:\n",
    "    print(round(len(sub_DF), 2), \"-> /5 ->\", round(len(sub_DF) / 5, 2))\n",
    "    print(round(len(sub_DF) * 0.7, 2), \"-> *.7/5 > \", round(len(sub_DF) *0.7 / 5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64172093-46ff-493f-ad9f-29716bff94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\", \"outputs\", \"train_and_test_ids.json\"), 'r') as f:\n",
    "    split_with_ids = json.load(f)\n",
    "\n",
    "testset_ratio = (\n",
    "    len(split_with_ids[\"Test\"]) / (len(split_with_ids[\"Train\"]) + len(split_with_ids[\"Test\"]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed93350-14a7-47ac-aca6-6347e6b30822",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_DF in sub_DF_list:\n",
    "    print(\n",
    "        len([ x for x in split_with_ids[\"Train\"] if x in sub_DF[\"ID\"].values ]), \n",
    "        len([ x for x in split_with_ids[\"Test\"] if x in sub_DF[\"ID\"].values ])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5873fd3-880f-4626-a3f6-e6416e1196cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(126 / 5)\n",
    "print(169 / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebee20b-b2b4-4c68-b640-967cc908e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([ \"_\".join(f.split(\"_\")[:3]) for f in DF.columns ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe03788-d17a-482d-afdf-1b2e75c0ba89",
   "metadata": {},
   "source": [
    "## Check outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1c45b-9803-4719-a3c5-a862b6afc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from age_pred_model import FeatureReducer\n",
    "from factor_analyzer import Rotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0ced2-441e-4f99-b194-d63501dad2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.path.join(\"..\", \"outputs\", \"2025-08-13_original_sex-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21ebea-767f-47a3-b2bd-5858604f19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = [\"le-44\", \"ge-45\"][0]\n",
    "ori_name = [\"STRUCTURE\", \"BEH\", \"FUNCTIONAL\", \"ALL\"][-1]\n",
    "\n",
    "reducer_path = os.path.join(out_dir, \"reducer_{}_{}.pkl\".format(group_name, ori_name))\n",
    "# pc_loadings_path = os.path.join(out_dir, \"PC_loadings_{}_{}.xlsx\".format(group_name, ori_name))\n",
    "# rc_loadings_path = os.path.join(out_dir, \"RC_loadings_{}_{}.xlsx\".format(group_name, ori_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487a9c0-88ba-42eb-ab9f-4a8484e7feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(reducer_path, 'rb') as f:\n",
    "    reducer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9b55c-ac70-479a-b7c6-e5fbf47770e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for f in reducer.fitted_pca.keys():\n",
    "#     eigenvectors = reducer.fitted_pca[f].components_.T\n",
    "#     # print(np.linalg.norm(eigenvectors, axis=0))\n",
    "\n",
    "#     eigenvalues = reducer.fitted_pca[f].explained_variance_\n",
    "#     loadings = eigenvectors * np.sqrt(eigenvalues)\n",
    "\n",
    "#     if loadings.shape[1] > 1: # Apply varimax rotation\n",
    "#         rotator = Rotator(method=\"varimax\")\n",
    "#         rotated_loadings = rotator.fit_transform(np.array(loadings))\n",
    "#         rotated_scores = np.linalg.pinv(rotated_loadings.T)\n",
    "#         print(np.linalg.norm(rotated_scores, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfb1c6-c892-48be-b1f1-1c7d0ac845b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in reducer.rotated_components.keys():\n",
    "#     print(np.linalg.norm(reducer.rotated_components[f], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c98c07-2afb-4289-a7db-e1176f34a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = [\"le-44\", \"ge-45\"][0]\n",
    "ori_name = [\"STRUCTURE\", \"BEH\", \"FUNCTIONAL\", \"ALL\"][-1]\n",
    "\n",
    "feature_importances = pd.read_csv(\n",
    "    os.path.join(out_dir, \"features_{}_{}.csv\".format(group_name, ori_name)), \n",
    "    header=None\n",
    ")\n",
    "feature_importances.sort_values(by=1, ascending=False, key=abs, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbeaa75-5bad-432c-8034-6cba38fbbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "6 / 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0bba63-0164-4f8d-a76a-d5a98e93362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_importances)\n",
    "\n",
    "# 20 6\n",
    "# 40 12\n",
    "# 100 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8a8d7-a5bb-4492-9a96-64ed9a75bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(8, 30))\n",
    "sns.barplot(x=1, y=0, data=feature_importances)\n",
    "ax.set(xlim=(-1, 1), \n",
    "       ylabel=\"\",\n",
    "       xlabel=\"feature importances\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05511c8b-5b08-4f0d-ab8c-db080aa50856",
   "metadata": {},
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308b1b6f-f26f-4aa2-aed1-12d1ace004d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, entropy \n",
    "from statsmodels.stats.multitest import fdrcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136a16ca-6e25-4616-9283-28f2b368a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"src\"))\n",
    "from utils import basic_Q_features, ST_features\n",
    "\n",
    "basic_q_features = basic_Q_features()\n",
    "st_features = ST_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33da5e6e-cef4-4b6d-9757-a8496936c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annot_mat(cormat, p_stacked, fdr):\n",
    "    _, q_vals = fdrcorrection(p_stacked.dropna().values, alpha=fdr)\n",
    "    q_stacked = pd.Series(q_vals, index=p_stacked.index)\n",
    "    q_mat = q_stacked.unstack()\n",
    "    q_sig = q_mat.applymap(lambda x: \"\".join([\"*\" for t in [.05, .01, .001] if x <= t]))\n",
    "    annot_mat = cormat.round(2).astype(str) + q_sig\n",
    "    return annot_mat.fillna(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e22ecc2c-f37b-4915-a5bf-9bd2d45f6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF.loc[:, [\"ID\"] + basic_q_features + st_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69e9caa5-ae8e-472e-a3e1-e4a6da97a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _format_r(x, y, nt):\n",
    "#     if np.std(x) == 0 or np.std(y) == 0:\n",
    "#         return \"N/A\"\n",
    "#     else:\n",
    "#         r, p = pearsonr(x, y, alternative='two-sided')\n",
    "#         if p < .001:\n",
    "#             return f\"{r:.2f}***\"\n",
    "#         elif p < .01:\n",
    "#             return f\"{r:.2f}**\"\n",
    "#         elif p < .05:\n",
    "#             return f\"{r:.2f}*\"\n",
    "#         else:\n",
    "#             return f\"{r:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b475de-f5b8-45dc-9352-e41d4e1d382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annot_mat = pd.DataFrame(index=cormat.index, columns=cormat.columns, dtype=str)\n",
    "# for t1 in cormat.index:\n",
    "#     for t2 in cormat.columns:\n",
    "#         annot_mat.loc[t1, t2] = _format_r(DF[t1], DF[t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a8b78ab-9f23-428d-8a87-63d52ab77756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_mat = DF[st_features].corr(method=lambda x, y: pearsonr(x, y)[1] if np.std(x) > 0 and np.std(y) > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ed0f328-2ad4-4017-8767-27be4d00691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.tril(np.ones(p_mat.shape), k=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
